# =============================================================================
# Conseil des IA - Configuration
# Copiez ce fichier en .env et remplissez vos clés API
# =============================================================================

# --- Application ---
ENVIRONMENT=development
DEBUG=true
HOST=0.0.0.0
PORT=8080

# --- Logging ---
LOG_LEVEL=DEBUG
LOG_FORMAT=text
# LOG_FILE=logs/conseil-ia.log

# --- Clés API (remplissez celles que vous avez) ---
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
MISTRAL_API_KEY=
COHERE_API_KEY=
DEEPSEEK_API_KEY=

# --- Google Cloud / Gemini ---
GOOGLE_CLOUD_PROJECT=
GCP_PROJECT_ID=
GCP_REGION=europe-west1
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# --- Ollama (Modèles Locaux) ---
OLLAMA_ENABLED=false
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# --- Cache ---
CACHE_ENABLED=true
CACHE_TTL=3600
FIRESTORE_COLLECTION=conseil_cache

# --- Rate Limiting ---
RATE_LIMIT_PER_MINUTE=20
MAX_COST_PER_USER_PER_DAY=5.0

# --- CORS ---
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]

# --- Streaming ---
ENABLE_STREAMING=true

# --- Prompts ---
PROMPT_OPTIMIZATION_ENABLED=true
MAX_TOKENS=4000
DEFAULT_TEMPERATURE=0.7
REQUEST_TIMEOUT=30
